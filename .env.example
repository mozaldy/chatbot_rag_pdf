# --- Application Settings ---
API_TITLE="Local RAG API"

# --- Qdrant Configuration ---
QDRANT_HOST="localhost"
QDRANT_PORT=6333
COLLECTION_NAME="pdf_rag"

# --- Embedding Models ---
# Dense Model (Standard: BAAI/bge-m3)
EMBEDDING_MODEL="BAAI/bge-m3"

# --- Chunking Configuration ---
# Chunk size in tokens (larger = more context, smaller = more precise)
# Recommended: 512 for technical docs, 256-384 for Q&A
CHUNK_SIZE=512
# Overlap between chunks (prevents information loss at boundaries)
# Recommended: 20-30% of chunk size
CHUNK_OVERLAP=128

# --- PDF Processing ---
# Set to True if you need to read text inside images/scans
ENABLE_OCR=False

# --- LLM Configuration (Main Inference) ---
# Options: "ollama", "openai", "anthropic", "gemini"
LLM_PROVIDER="ollama"
# Model examples: "gemma3:4b", "gpt-4o", "claude-3-opus", "gemini-2.0-flash"
LLM_MODEL="gemma3:4b"

# --- LLM Configuration (Fast/Enrichment) ---
# Used for document summarization and chunk enrichment
FAST_LLM_PROVIDER="ollama"
FAST_LLM_MODEL="gemma3:4b"

# --- Provider Specific Settings ---

# Ollama
OLLAMA_BASE_URL="http://localhost:11434"
OLLAMA_TIMEOUT=120.0

# OpenAI
# OPENAI_API_KEY="sk-..."

# Anthropic
# ANTHROPIC_API_KEY="sk-ant-..."

# Google Gemini
# GOOGLE_API_KEY="AIza..."
